{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data (replies already been excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tweets (excludes replies) before data pre-processing: 6501\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import pandas as pd\n",
    "\n",
    "text = pd.read_csv('Jan6(excludes replies).csv')\n",
    "text2 = pd.read_csv('Frey transcripts.csv')\n",
    "print('The number of tweets (excludes replies) before data pre-processing:',len(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = text2.dropna()\n",
    "# text2 = text2.drop(columns=\"url\")\n",
    "text2.rename(columns = {'tweets':'transcripts', 'Company':'transcript_name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>transcripts</th>\n",
       "      <th>date</th>\n",
       "      <th>transcript_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Scene 4\\n\\nLars: [00:15:35] 35. [00:15:30]\\n\\n...</td>\n",
       "      <td>1/5/21 15:59</td>\n",
       "      <td>transcript 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>scene_2.wav\\nElizabeth: [00:00:01] This is my ...</td>\n",
       "      <td>12/30/20 23:14</td>\n",
       "      <td>transcript 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>scene_3.wav\\nLindsey: [00:00:03] Before I was ...</td>\n",
       "      <td>12/23/20 19:00</td>\n",
       "      <td>transcript 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Scene 4\\n\\nLars: [00:15:35] 35. [00:15:30]\\n\\n...</td>\n",
       "      <td>12/16/20 21:26</td>\n",
       "      <td>transcript 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Scene 5\\n\\nElizabeth: [00:21:32] So [00:21:30]...</td>\n",
       "      <td>12/15/20 20:16</td>\n",
       "      <td>transcript 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Scene 6\\n\\nMaynard: [00:26:28] I noticed water...</td>\n",
       "      <td>12/10/20 0:24</td>\n",
       "      <td>transcript 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Scene 7\\n\\nLars: [00:28:45] Hey, [00:28:30] gu...</td>\n",
       "      <td>12/8/20 0:13</td>\n",
       "      <td>transcript 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Scene 8\\n\\nLindsey: [00:31:10] I [00:31:00] ju...</td>\n",
       "      <td>12/5/20 14:13</td>\n",
       "      <td>transcript 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Scene 9\\n\\nLindsey: [00:32:51] Probably. Just ...</td>\n",
       "      <td>12/3/20 23:32</td>\n",
       "      <td>transcript 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Scene 10\\n\\nLindsey: [00:36:15] Oh, yeah.\\n\\nL...</td>\n",
       "      <td>11/26/20 22:05</td>\n",
       "      <td>transcript 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.0</td>\n",
       "      <td>Scene 11\\n\\nLars: [00:41:00] You [00:41:00] gu...</td>\n",
       "      <td>11/24/20 20:57</td>\n",
       "      <td>transcript 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.0</td>\n",
       "      <td>Scene 12\\n\\nRyan: [00:44:04] feet [00:44:00] d...</td>\n",
       "      <td>11/18/20 22:50</td>\n",
       "      <td>transcript 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Scene 13\\n\\nElizabeth: [00:44:53] We are kind ...</td>\n",
       "      <td>11/9/20 18:47</td>\n",
       "      <td>transcript 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.0</td>\n",
       "      <td>Scene 14\\n\\nLars: [00:47:43] You [00:47:30] wa...</td>\n",
       "      <td>10/30/20 20:16</td>\n",
       "      <td>transcript 14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                        transcripts  \\\n",
       "0          0.0  Scene 4\\n\\nLars: [00:15:35] 35. [00:15:30]\\n\\n...   \n",
       "1          1.0  scene_2.wav\\nElizabeth: [00:00:01] This is my ...   \n",
       "2          2.0  scene_3.wav\\nLindsey: [00:00:03] Before I was ...   \n",
       "3          4.0  Scene 4\\n\\nLars: [00:15:35] 35. [00:15:30]\\n\\n...   \n",
       "4          5.0  Scene 5\\n\\nElizabeth: [00:21:32] So [00:21:30]...   \n",
       "5          6.0  Scene 6\\n\\nMaynard: [00:26:28] I noticed water...   \n",
       "6          8.0  Scene 7\\n\\nLars: [00:28:45] Hey, [00:28:30] gu...   \n",
       "7          9.0  Scene 8\\n\\nLindsey: [00:31:10] I [00:31:00] ju...   \n",
       "8         10.0  Scene 9\\n\\nLindsey: [00:32:51] Probably. Just ...   \n",
       "9         11.0  Scene 10\\n\\nLindsey: [00:36:15] Oh, yeah.\\n\\nL...   \n",
       "10        12.0  Scene 11\\n\\nLars: [00:41:00] You [00:41:00] gu...   \n",
       "11        14.0  Scene 12\\n\\nRyan: [00:44:04] feet [00:44:00] d...   \n",
       "12        15.0  Scene 13\\n\\nElizabeth: [00:44:53] We are kind ...   \n",
       "13        16.0  Scene 14\\n\\nLars: [00:47:43] You [00:47:30] wa...   \n",
       "\n",
       "              date transcript_name  \n",
       "0     1/5/21 15:59    transcript 1  \n",
       "1   12/30/20 23:14    transcript 2  \n",
       "2   12/23/20 19:00    transcript 3  \n",
       "3   12/16/20 21:26    transcript 4  \n",
       "4   12/15/20 20:16    transcript 5  \n",
       "5    12/10/20 0:24    transcript 6  \n",
       "6     12/8/20 0:13    transcript 7  \n",
       "7    12/5/20 14:13    transcript 8  \n",
       "8    12/3/20 23:32    transcript 9  \n",
       "9   11/26/20 22:05   transcript 10  \n",
       "10  11/24/20 20:57   transcript 11  \n",
       "11  11/18/20 22:50   transcript 12  \n",
       "12   11/9/20 18:47   transcript 13  \n",
       "13  10/30/20 20:16   transcript 14  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lda import guidedlda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Cleaning\n",
    "1. tokenization\n",
    "2. remove @users, hashtag symbols, Urls, and special symbols(i.e., '&amp'), non-alphabetic characters, and words that have less than 3 characters\n",
    "3. remove stopwords\n",
    "4. lowercase transformation\n",
    "5. stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tweets after cleaning: 14\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import re\n",
    "porter = PorterStemmer()\n",
    "stop_words = stopwords.words('english')\n",
    "b = []\n",
    "for i,u in text2.iterrows():\n",
    "    a = []\n",
    "    word =''\n",
    "    for words in str(u['transcripts']).split(): #tokenization\n",
    "        if '@' not in words: #remove @users\n",
    "            words = words.replace('#','') #remove hashtag symbol\n",
    "            if '#' not in words:\n",
    "                if 'http' not in words: #remove URLs\n",
    "                    if'&amp' not in words: #remove symbol\n",
    "                        words = re.sub(r'[^a-zA-Z]', ' ', words)#remove non-alphabetic characters\n",
    "                        if len(words)>2:\n",
    "                            word += (words+' ')\n",
    "    doc = ''\n",
    "    for token in word.split():\n",
    "        if len(token) >2: # remove words that have less than 3 characters\n",
    "            token = token.lower()# lowercase form\n",
    "            if token not in stop_words:# remove stopwords\n",
    "                token = porter.stem(token) #stemming\n",
    "                doc += (token+' ')\n",
    "    b.append(doc)\n",
    "text2['processed']=[i for i in b]\n",
    "\n",
    "# exclude tweets that are not in English\n",
    "non_english_list = ['temiz','rkiy','erik','nda','konu','dan','da','ba','al','viand','para','na','dann','uft','laboratorio','dieser','kalbimi',\n",
    "                   'restoranda','evento','komo','ind','tica','futuro','sonra','yla','cre','ili','daki',\n",
    "                   'zaman']\n",
    "index_axis = []\n",
    "for index,i in text2.iterrows():\n",
    "    if len(i['processed']) == 0:\n",
    "        index_axis.append(index)\n",
    "    else:\n",
    "        for word in i['processed'].split():\n",
    "            if word in non_english_list:\n",
    "                index_axis.append(index)\n",
    "                break\n",
    "text2.drop(text2.index[index_axis],inplace=True)\n",
    "print(\"number of tweets after cleaning:\",len(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transcript_name\n",
       "transcript 1     1\n",
       "transcript 10    1\n",
       "transcript 11    1\n",
       "transcript 12    1\n",
       "transcript 13    1\n",
       "transcript 14    1\n",
       "transcript 2     1\n",
       "transcript 3     1\n",
       "transcript 4     1\n",
       "transcript 5     1\n",
       "transcript 6     1\n",
       "transcript 7     1\n",
       "transcript 8     1\n",
       "transcript 9     1\n",
       "Name: transcripts, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2.groupby('transcript_name')['transcripts'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly Select 20% Dataset As Our Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_random_20percent = text2.sample(frac=0.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transcript_name\n",
       "transcript 10    1\n",
       "transcript 4     1\n",
       "transcript 6     1\n",
       "Name: transcripts, dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_random_20percent.groupby('transcript_name')['transcripts'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:collecting all words and their counts\n",
      "INFO:gensim.models.phrases:PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO:gensim.models.phrases:collected 791 token types (unigram + bigrams) from a corpus of 518 words and 3 sentences\n",
      "INFO:gensim.models.phrases:merged Phrases<791 vocab, min_count=1, threshold=1, max_vocab_size=40000000>\n",
      "INFO:gensim.utils:Phrases lifecycle event {'msg': 'built Phrases<791 vocab, min_count=1, threshold=1, max_vocab_size=40000000> in 0.01s', 'datetime': '2022-07-18T19:45:57.546822', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "INFO:gensim.models.phrases:exporting phrases from Phrases<791 vocab, min_count=1, threshold=1, max_vocab_size=40000000>\n",
      "INFO:gensim.utils:FrozenPhrases lifecycle event {'msg': 'exported FrozenPhrases<22 phrases, min_count=1, threshold=1> from Phrases<791 vocab, min_count=1, threshold=1, max_vocab_size=40000000> in 0.00s', 'datetime': '2022-07-18T19:45:57.553856', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n",
      "INFO:gensim.corpora.dictionary:built Dictionary<307 unique tokens: ['adult', 'age', 'alaska', 'alison', 'also']...> from 3 documents (total 485 corpus positions)\n",
      "INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<307 unique tokens: ['adult', 'age', 'alaska', 'alison', 'also']...> from 3 documents (total 485 corpus positions)\", 'datetime': '2022-07-18T19:45:57.558368', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.1\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.1\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 3 documents, updating model once every 3 documents, evaluating perplexity every 3 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO:gensim.models.ldamodel:-13.430 per-word bound, 11037.0 perplexity estimate based on a held-out corpus of 3 documents with 485 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #3/3\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.007*\"deni\" + 0.006*\"lar\" + 0.005*\"like\" + 0.005*\"peopl\" + 0.005*\"yeah\" + 0.005*\"longer\" + 0.005*\"cancer\" + 0.005*\"diagnos\" + 0.005*\"lost\" + 0.005*\"know\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.004*\"deni\" + 0.004*\"lar\" + 0.004*\"hello\" + 0.004*\"know\" + 0.004*\"michel\" + 0.004*\"cancer\" + 0.004*\"peopl\" + 0.004*\"past\" + 0.004*\"diagnos\" + 0.004*\"yeah\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.021*\"lindsey\" + 0.016*\"right\" + 0.012*\"like\" + 0.012*\"roy\" + 0.011*\"deni\" + 0.011*\"got\" + 0.011*\"guy\" + 0.011*\"lar\" + 0.010*\"mirror\" + 0.010*\"welcom\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.031*\"lindsey\" + 0.014*\"right\" + 0.014*\"like\" + 0.013*\"mirror\" + 0.013*\"roy\" + 0.013*\"got\" + 0.012*\"welcom\" + 0.012*\"word\" + 0.011*\"guy\" + 0.010*\"life\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.015*\"like\" + 0.014*\"peopl\" + 0.012*\"right\" + 0.012*\"notic\" + 0.010*\"lar\" + 0.010*\"deni\" + 0.009*\"one\" + 0.009*\"would\" + 0.008*\"longer\" + 0.008*\"diagnos\"\n",
      "INFO:gensim.models.ldamodel:topic diff=4.121758, rho=1.000000\n",
      "INFO:gensim.utils:LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=307, num_topics=10, decay=0.5, chunksize=2000> in 0.02s', 'datetime': '2022-07-18T19:45:57.596341', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.09090909090909091\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.09090909090909091\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (single-pass) LDA training, 11 topics, 1 passes over the supplied corpus of 3 documents, updating model once every 3 documents, evaluating perplexity every 3 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO:gensim.models.ldamodel:-14.608 per-word bound, 24972.6 perplexity estimate based on a held-out corpus of 3 documents with 485 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #3/3\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.091): 0.012*\"deni\" + 0.010*\"right\" + 0.010*\"like\" + 0.010*\"lar\" + 0.009*\"phil\" + 0.008*\"know\" + 0.008*\"got\" + 0.008*\"yeah\" + 0.008*\"cancer\" + 0.008*\"hello\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.091): 0.019*\"lar\" + 0.013*\"deni\" + 0.011*\"right\" + 0.011*\"know\" + 0.009*\"michel\" + 0.009*\"yeah\" + 0.009*\"cancer\" + 0.009*\"like\" + 0.009*\"diagnos\" + 0.008*\"one\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.091): 0.013*\"peopl\" + 0.012*\"notic\" + 0.010*\"come_visit\" + 0.010*\"would\" + 0.010*\"everyon\" + 0.009*\"quiet\" + 0.008*\"see_butterfli\" + 0.008*\"butterfli\" + 0.008*\"light\" + 0.007*\"tattoo\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.091): 0.015*\"lar\" + 0.012*\"lindsey\" + 0.011*\"deni\" + 0.010*\"right\" + 0.009*\"know\" + 0.009*\"think\" + 0.009*\"got\" + 0.007*\"one\" + 0.007*\"like\" + 0.007*\"roy\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.091): 0.013*\"lar\" + 0.013*\"deni\" + 0.008*\"diagnos\" + 0.008*\"peopl\" + 0.008*\"like\" + 0.008*\"right\" + 0.008*\"cancer\" + 0.008*\"yeah\" + 0.007*\"way\" + 0.007*\"one\"\n",
      "INFO:gensim.models.ldamodel:topic diff=4.521856, rho=1.000000\n",
      "INFO:gensim.utils:LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=307, num_topics=11, decay=0.5, chunksize=2000> in 0.01s', 'datetime': '2022-07-18T19:45:57.620492', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.08333333333333333\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.08333333333333333\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (single-pass) LDA training, 12 topics, 1 passes over the supplied corpus of 3 documents, updating model once every 3 documents, evaluating perplexity every 3 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO:gensim.models.ldamodel:-15.849 per-word bound, 59006.2 perplexity estimate based on a held-out corpus of 3 documents with 485 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #3/3\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.083): 0.014*\"deni\" + 0.011*\"like\" + 0.010*\"right\" + 0.010*\"lar\" + 0.009*\"phil\" + 0.009*\"know\" + 0.008*\"got\" + 0.008*\"yeah\" + 0.008*\"cancer\" + 0.008*\"time\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.083): 0.011*\"lar\" + 0.011*\"deni\" + 0.007*\"yeah\" + 0.007*\"cancer\" + 0.006*\"know\" + 0.006*\"michel\" + 0.006*\"past\" + 0.006*\"like\" + 0.006*\"diagnos\" + 0.006*\"hello\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.083): 0.018*\"lar\" + 0.012*\"deni\" + 0.012*\"know\" + 0.010*\"right\" + 0.009*\"lindsey\" + 0.009*\"think\" + 0.009*\"hello\" + 0.009*\"got\" + 0.008*\"michel\" + 0.008*\"yeah\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.083): 0.019*\"lar\" + 0.014*\"right\" + 0.014*\"deni\" + 0.011*\"like\" + 0.011*\"one\" + 0.010*\"yeah\" + 0.009*\"know\" + 0.009*\"lindsey\" + 0.009*\"phil\" + 0.008*\"got\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.083): 0.015*\"like\" + 0.014*\"right\" + 0.014*\"lar\" + 0.012*\"deni\" + 0.011*\"peopl\" + 0.009*\"know\" + 0.009*\"notic\" + 0.009*\"one\" + 0.009*\"life\" + 0.009*\"diagnos\"\n",
      "INFO:gensim.models.ldamodel:topic diff=5.308731, rho=1.000000\n",
      "INFO:gensim.utils:LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=307, num_topics=12, decay=0.5, chunksize=2000> in 0.01s', 'datetime': '2022-07-18T19:45:57.641697', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.07692307692307693\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.07692307692307693\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (single-pass) LDA training, 13 topics, 1 passes over the supplied corpus of 3 documents, updating model once every 3 documents, evaluating perplexity every 3 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO:gensim.models.ldamodel:-17.146 per-word bound, 144997.4 perplexity estimate based on a held-out corpus of 3 documents with 485 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #3/3\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.077): 0.014*\"lindsey\" + 0.014*\"lar\" + 0.013*\"deni\" + 0.013*\"right\" + 0.010*\"like\" + 0.010*\"yeah\" + 0.010*\"way\" + 0.009*\"time\" + 0.009*\"think\" + 0.009*\"got\"\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.077): 0.016*\"notic\" + 0.014*\"would\" + 0.014*\"peopl\" + 0.014*\"come_visit\" + 0.013*\"see_butterfli\" + 0.012*\"like\" + 0.011*\"alway\" + 0.011*\"everyon\" + 0.011*\"one\" + 0.011*\"light\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.077): 0.016*\"deni\" + 0.012*\"lar\" + 0.011*\"know\" + 0.010*\"hello\" + 0.010*\"like\" + 0.009*\"right\" + 0.009*\"michel\" + 0.009*\"cancer\" + 0.009*\"diagnos\" + 0.009*\"anyth\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.077): 0.003*\"peopl\" + 0.003*\"like\" + 0.003*\"deni\" + 0.003*\"notic\" + 0.003*\"lindsey\" + 0.003*\"life\" + 0.003*\"right\" + 0.003*\"one\" + 0.003*\"way\" + 0.003*\"time\"\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.077): 0.024*\"notic\" + 0.022*\"peopl\" + 0.014*\"would\" + 0.014*\"tattoo\" + 0.014*\"butterfli\" + 0.014*\"one\" + 0.013*\"everyon\" + 0.013*\"understand\" + 0.013*\"come_visit\" + 0.012*\"like\"\n",
      "INFO:gensim.models.ldamodel:topic diff=6.398907, rho=1.000000\n",
      "INFO:gensim.utils:LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=307, num_topics=13, decay=0.5, chunksize=2000> in 0.01s', 'datetime': '2022-07-18T19:45:57.666094', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.07142857142857142\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.07142857142857142\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (single-pass) LDA training, 14 topics, 1 passes over the supplied corpus of 3 documents, updating model once every 3 documents, evaluating perplexity every 3 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO:gensim.models.ldamodel:-18.462 per-word bound, 361058.7 perplexity estimate based on a held-out corpus of 3 documents with 485 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #3/3\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.071): 0.003*\"like\" + 0.003*\"peopl\" + 0.003*\"right\" + 0.003*\"deni\" + 0.003*\"would\" + 0.003*\"notic\" + 0.003*\"phil\" + 0.003*\"yeah\" + 0.003*\"roy\" + 0.003*\"light\"\n",
      "INFO:gensim.models.ldamodel:topic #13 (0.071): 0.021*\"peopl\" + 0.020*\"notic\" + 0.017*\"would\" + 0.014*\"one\" + 0.013*\"deni\" + 0.013*\"like\" + 0.012*\"see_butterfli\" + 0.012*\"quiet\" + 0.011*\"alway\" + 0.011*\"everyon\"\n",
      "INFO:gensim.models.ldamodel:topic #3 (0.071): 0.014*\"lar\" + 0.014*\"deni\" + 0.009*\"cancer\" + 0.009*\"yeah\" + 0.008*\"know\" + 0.008*\"michel\" + 0.007*\"past\" + 0.007*\"lost\" + 0.007*\"like\" + 0.007*\"diagnos\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.071): 0.025*\"lindsey\" + 0.016*\"right\" + 0.013*\"roy\" + 0.012*\"like\" + 0.012*\"deni\" + 0.012*\"mirror\" + 0.012*\"got\" + 0.011*\"lar\" + 0.011*\"word\" + 0.011*\"guy\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.071): 0.012*\"would\" + 0.011*\"notic\" + 0.008*\"peopl\" + 0.008*\"deni\" + 0.008*\"like\" + 0.008*\"light\" + 0.007*\"quiet\" + 0.007*\"alway\" + 0.007*\"understand\" + 0.007*\"one\"\n",
      "INFO:gensim.models.ldamodel:topic diff=6.518118, rho=1.000000\n",
      "INFO:gensim.utils:LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=307, num_topics=14, decay=0.5, chunksize=2000> in 0.01s', 'datetime': '2022-07-18T19:45:57.688816', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.06666666666666667\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.06666666666666667\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (single-pass) LDA training, 15 topics, 1 passes over the supplied corpus of 3 documents, updating model once every 3 documents, evaluating perplexity every 3 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO:gensim.models.ldamodel:-19.852 per-word bound, 946098.1 perplexity estimate based on a held-out corpus of 3 documents with 485 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #3/3\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.067): 0.019*\"right\" + 0.017*\"lar\" + 0.015*\"like\" + 0.012*\"lindsey\" + 0.012*\"deni\" + 0.011*\"got\" + 0.010*\"know\" + 0.010*\"yeah\" + 0.010*\"guy\" + 0.009*\"cancer\"\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.067): 0.016*\"lar\" + 0.011*\"know\" + 0.010*\"deni\" + 0.008*\"right\" + 0.008*\"think\" + 0.008*\"hello\" + 0.008*\"michel\" + 0.007*\"first\" + 0.007*\"got\" + 0.007*\"yeah\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.067): 0.020*\"lar\" + 0.014*\"right\" + 0.014*\"deni\" + 0.011*\"yeah\" + 0.010*\"know\" + 0.010*\"like\" + 0.010*\"one\" + 0.010*\"phil\" + 0.009*\"cancer\" + 0.009*\"got\"\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.067): 0.013*\"deni\" + 0.013*\"lar\" + 0.010*\"like\" + 0.009*\"come\" + 0.009*\"hello\" + 0.009*\"right\" + 0.008*\"know\" + 0.008*\"peopl\" + 0.008*\"michel\" + 0.008*\"diagnos\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.067): 0.016*\"lar\" + 0.014*\"deni\" + 0.013*\"right\" + 0.013*\"lindsey\" + 0.011*\"yeah\" + 0.010*\"time\" + 0.010*\"like\" + 0.010*\"think\" + 0.010*\"way\" + 0.009*\"got\"\n",
      "INFO:gensim.models.ldamodel:topic diff=7.169794, rho=1.000000\n",
      "INFO:gensim.utils:LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=307, num_topics=15, decay=0.5, chunksize=2000> in 0.01s', 'datetime': '2022-07-18T19:45:57.711310', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.0625\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.0625\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (single-pass) LDA training, 16 topics, 1 passes over the supplied corpus of 3 documents, updating model once every 3 documents, evaluating perplexity every 3 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO:gensim.models.ldamodel:-21.270 per-word bound, 2528685.1 perplexity estimate based on a held-out corpus of 3 documents with 485 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #3/3\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.062): 0.013*\"deni\" + 0.011*\"lar\" + 0.010*\"know\" + 0.009*\"like\" + 0.009*\"right\" + 0.009*\"cancer\" + 0.009*\"hello\" + 0.008*\"michel\" + 0.008*\"diagnos\" + 0.008*\"anyth\"\n",
      "INFO:gensim.models.ldamodel:topic #10 (0.062): 0.016*\"lar\" + 0.014*\"deni\" + 0.012*\"like\" + 0.011*\"know\" + 0.011*\"lost\" + 0.010*\"yeah\" + 0.010*\"diagnos\" + 0.009*\"cancer\" + 0.009*\"four\" + 0.009*\"back_forth\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.062): 0.013*\"lar\" + 0.013*\"right\" + 0.011*\"like\" + 0.009*\"deni\" + 0.009*\"know\" + 0.008*\"cancer\" + 0.008*\"yeah\" + 0.007*\"got\" + 0.007*\"hello\" + 0.007*\"life\"\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.062): 0.037*\"lindsey\" + 0.017*\"right\" + 0.015*\"word\" + 0.015*\"mirror\" + 0.015*\"roy\" + 0.015*\"welcom\" + 0.014*\"like\" + 0.014*\"got\" + 0.013*\"guy\" + 0.011*\"yeah\"\n",
      "INFO:gensim.models.ldamodel:topic #13 (0.062): 0.019*\"peopl\" + 0.016*\"notic\" + 0.012*\"one\" + 0.011*\"would\" + 0.011*\"deni\" + 0.011*\"like\" + 0.009*\"see_butterfli\" + 0.009*\"lar\" + 0.009*\"quiet\" + 0.009*\"diagnos\"\n",
      "INFO:gensim.models.ldamodel:topic diff=8.169583, rho=1.000000\n",
      "INFO:gensim.utils:LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=307, num_topics=16, decay=0.5, chunksize=2000> in 0.01s', 'datetime': '2022-07-18T19:45:57.734482', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.058823529411764705\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.058823529411764705\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (single-pass) LDA training, 17 topics, 1 passes over the supplied corpus of 3 documents, updating model once every 3 documents, evaluating perplexity every 3 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO:gensim.models.ldamodel:-22.728 per-word bound, 6949406.2 perplexity estimate based on a held-out corpus of 3 documents with 485 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #3/3\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.059): 0.025*\"notic\" + 0.021*\"would\" + 0.017*\"peopl\" + 0.015*\"like\" + 0.015*\"light\" + 0.014*\"quiet\" + 0.014*\"understand\" + 0.013*\"one\" + 0.013*\"alway\" + 0.012*\"come_visit\"\n",
      "INFO:gensim.models.ldamodel:topic #16 (0.059): 0.020*\"notic\" + 0.017*\"peopl\" + 0.016*\"would\" + 0.014*\"deni\" + 0.013*\"one\" + 0.012*\"like\" + 0.012*\"butterfli\" + 0.012*\"tattoo\" + 0.011*\"alway\" + 0.011*\"right\"\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.059): 0.019*\"notic\" + 0.017*\"come_visit\" + 0.016*\"peopl\" + 0.015*\"would\" + 0.014*\"see_butterfli\" + 0.014*\"everyon\" + 0.013*\"like\" + 0.013*\"alway\" + 0.012*\"light\" + 0.012*\"understand\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.059): 0.021*\"lindsey\" + 0.014*\"right\" + 0.011*\"roy\" + 0.011*\"guy\" + 0.010*\"mirror\" + 0.010*\"word\" + 0.010*\"welcom\" + 0.010*\"like\" + 0.009*\"got\" + 0.009*\"time_come\"\n",
      "INFO:gensim.models.ldamodel:topic #15 (0.059): 0.016*\"lindsey\" + 0.011*\"mirror\" + 0.011*\"right\" + 0.011*\"like\" + 0.011*\"welcom\" + 0.010*\"got\" + 0.009*\"deni\" + 0.009*\"yeah\" + 0.009*\"word\" + 0.009*\"one\"\n",
      "INFO:gensim.models.ldamodel:topic diff=8.892001, rho=1.000000\n",
      "INFO:gensim.utils:LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=307, num_topics=17, decay=0.5, chunksize=2000> in 0.01s', 'datetime': '2022-07-18T19:45:57.757996', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.05555555555555555\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.05555555555555555\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (single-pass) LDA training, 18 topics, 1 passes over the supplied corpus of 3 documents, updating model once every 3 documents, evaluating perplexity every 3 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO:gensim.models.ldamodel:-24.208 per-word bound, 19385500.8 perplexity estimate based on a held-out corpus of 3 documents with 485 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #3/3\n",
      "INFO:gensim.models.ldamodel:topic #11 (0.056): 0.003*\"onto\" + 0.003*\"notic\" + 0.003*\"probabl\" + 0.003*\"poppa\" + 0.003*\"pop\" + 0.003*\"part\" + 0.003*\"papa\" + 0.003*\"outdoor\" + 0.003*\"realli\" + 0.003*\"observ\"\n",
      "INFO:gensim.models.ldamodel:topic #17 (0.056): 0.020*\"lindsey\" + 0.017*\"like\" + 0.016*\"right\" + 0.012*\"mirror\" + 0.012*\"guy\" + 0.011*\"way\" + 0.010*\"deni\" + 0.010*\"got\" + 0.010*\"one\" + 0.009*\"welcom\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.056): 0.019*\"deni\" + 0.017*\"lindsey\" + 0.015*\"right\" + 0.015*\"lar\" + 0.014*\"like\" + 0.013*\"got\" + 0.013*\"way\" + 0.010*\"roy\" + 0.010*\"yeah\" + 0.009*\"one\"\n",
      "INFO:gensim.models.ldamodel:topic #7 (0.056): 0.028*\"lindsey\" + 0.018*\"right\" + 0.014*\"roy\" + 0.013*\"word\" + 0.012*\"guy\" + 0.012*\"welcom\" + 0.012*\"like\" + 0.012*\"mirror\" + 0.012*\"got\" + 0.011*\"time\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.056): 0.007*\"lar\" + 0.006*\"deni\" + 0.005*\"yeah\" + 0.005*\"cancer\" + 0.005*\"matt\" + 0.005*\"know\" + 0.005*\"diagnos\" + 0.004*\"time\" + 0.004*\"right\" + 0.004*\"michel\"\n",
      "INFO:gensim.models.ldamodel:topic diff=9.516623, rho=1.000000\n",
      "INFO:gensim.utils:LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=307, num_topics=18, decay=0.5, chunksize=2000> in 0.01s', 'datetime': '2022-07-18T19:45:57.782868', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.05263157894736842\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.05263157894736842\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (single-pass) LDA training, 19 topics, 1 passes over the supplied corpus of 3 documents, updating model once every 3 documents, evaluating perplexity every 3 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO:gensim.models.ldamodel:-25.709 per-word bound, 54858665.4 perplexity estimate based on a held-out corpus of 3 documents with 485 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #3/3\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.053): 0.014*\"deni\" + 0.012*\"lar\" + 0.012*\"know\" + 0.010*\"like\" + 0.010*\"right\" + 0.009*\"hello\" + 0.009*\"cancer\" + 0.009*\"michel\" + 0.009*\"diagnos\" + 0.009*\"yeah\"\n",
      "INFO:gensim.models.ldamodel:topic #8 (0.053): 0.015*\"lindsey\" + 0.009*\"right\" + 0.009*\"word\" + 0.008*\"guy\" + 0.008*\"welcom\" + 0.008*\"got\" + 0.008*\"mirror\" + 0.007*\"like\" + 0.007*\"roy\" + 0.007*\"know_heart\"\n",
      "INFO:gensim.models.ldamodel:topic #4 (0.053): 0.004*\"lar\" + 0.004*\"deni\" + 0.004*\"know\" + 0.004*\"hello\" + 0.004*\"michel\" + 0.004*\"cancer\" + 0.004*\"past\" + 0.004*\"yeah\" + 0.004*\"three\" + 0.004*\"diagnos\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.053): 0.017*\"lar\" + 0.014*\"deni\" + 0.012*\"right\" + 0.011*\"yeah\" + 0.010*\"time\" + 0.010*\"lindsey\" + 0.010*\"like\" + 0.009*\"think\" + 0.009*\"cancer\" + 0.009*\"way\"\n",
      "INFO:gensim.models.ldamodel:topic #12 (0.053): 0.010*\"lar\" + 0.010*\"deni\" + 0.009*\"like\" + 0.007*\"peopl\" + 0.007*\"come\" + 0.007*\"right\" + 0.007*\"hello\" + 0.007*\"know\" + 0.007*\"would\" + 0.006*\"michel\"\n",
      "INFO:gensim.models.ldamodel:topic diff=9.564266, rho=1.000000\n",
      "INFO:gensim.utils:LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=307, num_topics=19, decay=0.5, chunksize=2000> in 0.01s', 'datetime': '2022-07-18T19:45:57.807498', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.05\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.05\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (single-pass) LDA training, 20 topics, 1 passes over the supplied corpus of 3 documents, updating model once every 3 documents, evaluating perplexity every 3 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO:gensim.models.ldamodel:-27.269 per-word bound, 161756571.8 perplexity estimate based on a held-out corpus of 3 documents with 485 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #3/3\n",
      "INFO:gensim.models.ldamodel:topic #2 (0.050): 0.017*\"lar\" + 0.012*\"know\" + 0.011*\"deni\" + 0.009*\"think\" + 0.009*\"right\" + 0.008*\"hello\" + 0.008*\"michel\" + 0.007*\"yeah\" + 0.007*\"first\" + 0.007*\"cancer\"\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.050): 0.016*\"lar\" + 0.015*\"like\" + 0.013*\"right\" + 0.012*\"know\" + 0.012*\"deni\" + 0.011*\"peopl\" + 0.009*\"cancer\" + 0.009*\"time\" + 0.009*\"diagnos\" + 0.009*\"alison\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.050): 0.021*\"lar\" + 0.014*\"deni\" + 0.012*\"know\" + 0.010*\"right\" + 0.010*\"yeah\" + 0.010*\"michel\" + 0.010*\"cancer\" + 0.009*\"diagnos\" + 0.009*\"hello\" + 0.008*\"three\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.050): 0.018*\"deni\" + 0.015*\"lar\" + 0.010*\"right\" + 0.010*\"like\" + 0.010*\"way\" + 0.009*\"know\" + 0.009*\"cancer\" + 0.008*\"yeah\" + 0.008*\"got\" + 0.008*\"diagnos\"\n",
      "INFO:gensim.models.ldamodel:topic #10 (0.050): 0.017*\"lar\" + 0.014*\"deni\" + 0.012*\"like\" + 0.012*\"know\" + 0.011*\"yeah\" + 0.010*\"lost\" + 0.010*\"diagnos\" + 0.009*\"four\" + 0.009*\"think\" + 0.009*\"cancer\"\n",
      "INFO:gensim.models.ldamodel:topic diff=11.880806, rho=1.000000\n",
      "INFO:gensim.utils:LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=307, num_topics=20, decay=0.5, chunksize=2000> in 0.01s', 'datetime': '2022-07-18T19:45:57.831472', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence),deacc=True)) #tokenization，return a list\n",
    "data_words = list(sent_to_words(text_random_20percent['processed'])) #tokenization\n",
    "bigram = gensim.models.Phrases(data_words,min_count=1,threshold=1)\n",
    "'''mincount：int, the times that two unigram co-occur must be equal or higher than this number，\n",
    "threshold：Phrases function will return a 'phrase score', it will decide whether two unigrams can be regarded as a bigram'''\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram) # Bigram\n",
    "def make_bigrams(texts): #Bigram\n",
    "    return [bigram[doc] for doc in texts]\n",
    "data_words_bigrams = make_bigrams(data_words)\n",
    "id2word = corpora.Dictionary(data_words_bigrams)\n",
    "texts = data_words_bigrams\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start, step):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start,limit,step):\n",
    "        model=gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics,random_state=2022)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='u_mass')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values\n",
    "limit=21; start=10; step=1\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=texts, start=start, limit=limit, step=step)\n",
    "# Show graph\n",
    "# import matplotlib.pyplot as plt\n",
    "# x = range(start, limit, step)\n",
    "# plt.plot(x, coherence_values,label='20% random tweets')\n",
    "# plt.xlabel(\"Num Topics\")\n",
    "# plt.ylabel(\"Coherence score\")\n",
    "# plt.legend(loc='best')\n",
    "# plt.xticks(range(start,limit,step))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GuidedLDA Model\n",
    "latent topics are identified from the bigrams shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_words = [['god','hope','pray','believ','trust','church','convict','optim','religion','ideaolog','confid','group','relationship',\n",
    "      'mass','synagogu','anticip','futur','strong','lord','readi','wait','focu','posit','plan','support',\n",
    "      'desir','accept','loyal','truth','assent','assur','constant','credenc','credul',\n",
    "      'depend','fealti','relianc','sure','sureti','troth'],#0 Faith\n",
    "      ['tumor','radiolog','chemotherapi','benign','invas','masectomi','surgeri','malign','metastasi','melanoma',\n",
    "       'carcigen','cancer','precancer','survivor','diseas','sick','ill','spread','lump','cell','grow','neck','bodi',\n",
    "       'organ','lung','heal','emerg','oncologist','prescript','m.d.','test','pass','prognosi','migran','seizur','c.t.',\n",
    "       'scan','imag','heartbeat','diagnosi','biopsi','remov','carcinoma','big c'],#1 Cancer\n",
    "      ['earth','sun','sky','star','tree','flower','land','sea','ocean','lake','river','rain','storm','thunder',\n",
    "       'lighten','snow','sunset','sunris','outsid','leaf','trek','wilder','anim','stream','rock','bolt','flood',\n",
    "       'weather','water','hurrican','morn','night','world','life','environ','landscap','view','cosmo','countri','forest',\n",
    "       'macrocosm','outdoor','sceneri','seascap',\n",
    "       'set','univers','natur'],#2 Nature\n",
    "      ['reflect','care','self car','health','consider','conscienti','regard','thought','thougt','well',\n",
    "       'well-b','feel','mental health','introspect','meditat','center','concentr','breath','relax','sit','focu',\n",
    "       'yoga','bodi','hardship','redifin','experi','sign','know','heal',\n",
    "       'posit','mind','deep','bodi','sens','tension','paus','notic','heartbeat',\n",
    "       'heart','check','self-esteem','confid','alert','care',\n",
    "       'concern','direct','forethougt',\n",
    "       'head','heed','interest','pain','regard']]#3 Mindfullness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 14\n",
      "INFO:lda:vocab_size: 732\n",
      "INFO:lda:n_words: 2250\n",
      "INFO:lda:n_topics: 4\n",
      "INFO:lda:n_iter: 1000\n",
      "INFO:lda:<0> log likelihood: -20833\n",
      "INFO:lda:<10> log likelihood: -17102\n",
      "INFO:lda:<20> log likelihood: -16983\n",
      "INFO:lda:<30> log likelihood: -16908\n",
      "INFO:lda:<40> log likelihood: -16839\n",
      "INFO:lda:<50> log likelihood: -16830\n",
      "INFO:lda:<60> log likelihood: -16765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "believ  skipped\n",
      "trust  skipped\n",
      "church  skipped\n",
      "convict  skipped\n",
      "optim  skipped\n",
      "religion  skipped\n",
      "ideaolog  skipped\n",
      "mass  skipped\n",
      "synagogu  skipped\n",
      "anticip  skipped\n",
      "lord  skipped\n",
      "accept  skipped\n",
      "loyal  skipped\n",
      "truth  skipped\n",
      "assent  skipped\n",
      "assur  skipped\n",
      "constant  skipped\n",
      "credenc  skipped\n",
      "credul  skipped\n",
      "depend  skipped\n",
      "fealti  skipped\n",
      "relianc  skipped\n",
      "sure  skipped\n",
      "sureti  skipped\n",
      "troth  skipped\n",
      "radiolog  skipped\n",
      "benign  skipped\n",
      "invas  skipped\n",
      "masectomi  skipped\n",
      "malign  skipped\n",
      "metastasi  skipped\n",
      "melanoma  skipped\n",
      "carcigen  skipped\n",
      "precancer  skipped\n",
      "survivor  skipped\n",
      "diseas  skipped\n",
      "sick  skipped\n",
      "ill  skipped\n",
      "spread  skipped\n",
      "lump  skipped\n",
      "cell  skipped\n",
      "organ  skipped\n",
      "heal  skipped\n",
      "m.d.  skipped\n",
      "migran  skipped\n",
      "c.t.  skipped\n",
      "carcinoma  skipped\n",
      "big c  skipped\n",
      "sky  skipped\n",
      "tree  skipped\n",
      "sea  skipped\n",
      "ocean  skipped\n",
      "lake  skipped\n",
      "storm  skipped\n",
      "thunder  skipped\n",
      "lighten  skipped\n",
      "snow  skipped\n",
      "sunset  skipped\n",
      "leaf  skipped\n",
      "trek  skipped\n",
      "wilder  skipped\n",
      "anim  skipped\n",
      "stream  skipped\n",
      "bolt  skipped\n",
      "weather  skipped\n",
      "hurrican  skipped\n",
      "environ  skipped\n",
      "landscap  skipped\n",
      "view  skipped\n",
      "cosmo  skipped\n",
      "countri  skipped\n",
      "macrocosm  skipped\n",
      "sceneri  skipped\n",
      "seascap  skipped\n",
      "univers  skipped\n",
      "self car  skipped\n",
      "consider  skipped\n",
      "conscienti  skipped\n",
      "regard  skipped\n",
      "thougt  skipped\n",
      "well-b  skipped\n",
      "mental health  skipped\n",
      "introspect  skipped\n",
      "meditat  skipped\n",
      "center  skipped\n",
      "concentr  skipped\n",
      "relax  skipped\n",
      "yoga  skipped\n",
      "hardship  skipped\n",
      "redifin  skipped\n",
      "experi  skipped\n",
      "heal  skipped\n",
      "self-esteem  skipped\n",
      "alert  skipped\n",
      "concern  skipped\n",
      "direct  skipped\n",
      "forethougt  skipped\n",
      "head  skipped\n",
      "heed  skipped\n",
      "interest  skipped\n",
      "pain  skipped\n",
      "regard  skipped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:<70> log likelihood: -16716\n",
      "INFO:lda:<80> log likelihood: -16690\n",
      "INFO:lda:<90> log likelihood: -16729\n",
      "INFO:lda:<100> log likelihood: -16693\n",
      "INFO:lda:<110> log likelihood: -16721\n",
      "INFO:lda:<120> log likelihood: -16665\n",
      "INFO:lda:<130> log likelihood: -16581\n",
      "INFO:lda:<140> log likelihood: -16576\n",
      "INFO:lda:<150> log likelihood: -16526\n",
      "INFO:lda:<160> log likelihood: -16543\n",
      "INFO:lda:<170> log likelihood: -16424\n",
      "INFO:lda:<180> log likelihood: -16445\n",
      "INFO:lda:<190> log likelihood: -16427\n",
      "INFO:lda:<200> log likelihood: -16490\n",
      "INFO:lda:<210> log likelihood: -16416\n",
      "INFO:lda:<220> log likelihood: -16406\n",
      "INFO:lda:<230> log likelihood: -16360\n",
      "INFO:lda:<240> log likelihood: -16357\n",
      "INFO:lda:<250> log likelihood: -16391\n",
      "INFO:lda:<260> log likelihood: -16384\n",
      "INFO:lda:<270> log likelihood: -16371\n",
      "INFO:lda:<280> log likelihood: -16357\n",
      "INFO:lda:<290> log likelihood: -16377\n",
      "INFO:lda:<300> log likelihood: -16385\n",
      "INFO:lda:<310> log likelihood: -16347\n",
      "INFO:lda:<320> log likelihood: -16319\n",
      "INFO:lda:<330> log likelihood: -16361\n",
      "INFO:lda:<340> log likelihood: -16306\n",
      "INFO:lda:<350> log likelihood: -16344\n",
      "INFO:lda:<360> log likelihood: -16352\n",
      "INFO:lda:<370> log likelihood: -16287\n",
      "INFO:lda:<380> log likelihood: -16369\n",
      "INFO:lda:<390> log likelihood: -16325\n",
      "INFO:lda:<400> log likelihood: -16394\n",
      "INFO:lda:<410> log likelihood: -16439\n",
      "INFO:lda:<420> log likelihood: -16390\n",
      "INFO:lda:<430> log likelihood: -16403\n",
      "INFO:lda:<440> log likelihood: -16421\n",
      "INFO:lda:<450> log likelihood: -16349\n",
      "INFO:lda:<460> log likelihood: -16383\n",
      "INFO:lda:<470> log likelihood: -16382\n",
      "INFO:lda:<480> log likelihood: -16413\n",
      "INFO:lda:<490> log likelihood: -16368\n",
      "INFO:lda:<500> log likelihood: -16396\n",
      "INFO:lda:<510> log likelihood: -16323\n",
      "INFO:lda:<520> log likelihood: -16326\n",
      "INFO:lda:<530> log likelihood: -16289\n",
      "INFO:lda:<540> log likelihood: -16303\n",
      "INFO:lda:<550> log likelihood: -16245\n",
      "INFO:lda:<560> log likelihood: -16308\n",
      "INFO:lda:<570> log likelihood: -16349\n",
      "INFO:lda:<580> log likelihood: -16385\n",
      "INFO:lda:<590> log likelihood: -16355\n",
      "INFO:lda:<600> log likelihood: -16391\n",
      "INFO:lda:<610> log likelihood: -16352\n",
      "INFO:lda:<620> log likelihood: -16433\n",
      "INFO:lda:<630> log likelihood: -16382\n",
      "INFO:lda:<640> log likelihood: -16336\n",
      "INFO:lda:<650> log likelihood: -16340\n",
      "INFO:lda:<660> log likelihood: -16373\n",
      "INFO:lda:<670> log likelihood: -16345\n",
      "INFO:lda:<680> log likelihood: -16348\n",
      "INFO:lda:<690> log likelihood: -16284\n",
      "INFO:lda:<700> log likelihood: -16363\n",
      "INFO:lda:<710> log likelihood: -16326\n",
      "INFO:lda:<720> log likelihood: -16369\n",
      "INFO:lda:<730> log likelihood: -16286\n",
      "INFO:lda:<740> log likelihood: -16322\n",
      "INFO:lda:<750> log likelihood: -16344\n",
      "INFO:lda:<760> log likelihood: -16369\n",
      "INFO:lda:<770> log likelihood: -16349\n",
      "INFO:lda:<780> log likelihood: -16294\n",
      "INFO:lda:<790> log likelihood: -16350\n",
      "INFO:lda:<800> log likelihood: -16335\n",
      "INFO:lda:<810> log likelihood: -16374\n",
      "INFO:lda:<820> log likelihood: -16369\n",
      "INFO:lda:<830> log likelihood: -16330\n",
      "INFO:lda:<840> log likelihood: -16398\n",
      "INFO:lda:<850> log likelihood: -16358\n",
      "INFO:lda:<860> log likelihood: -16333\n",
      "INFO:lda:<870> log likelihood: -16343\n",
      "INFO:lda:<880> log likelihood: -16317\n",
      "INFO:lda:<890> log likelihood: -16325\n",
      "INFO:lda:<900> log likelihood: -16377\n",
      "INFO:lda:<910> log likelihood: -16296\n",
      "INFO:lda:<920> log likelihood: -16305\n",
      "INFO:lda:<930> log likelihood: -16281\n",
      "INFO:lda:<940> log likelihood: -16336\n",
      "INFO:lda:<950> log likelihood: -16363\n",
      "INFO:lda:<960> log likelihood: -16304\n",
      "INFO:lda:<970> log likelihood: -16259\n",
      "INFO:lda:<980> log likelihood: -16305\n",
      "INFO:lda:<990> log likelihood: -16248\n",
      "INFO:lda:<999> log likelihood: -16313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Topic: 0\n",
      "0.0631*right  0.057*yeah  0.0306*guid  0.0285*lar  0.0285*phil  0.0285*good  0.0285*come  0.0265*go  0.0244*guy  0.0224*one  0.0183*first  0.0163*okay  0.0143*put  0.0122*hope  0.0122*well  0.0122*let  0.0122*spot  0.0102*god  0.0102*start  0.0102*look  \n",
      "\n",
      "Topic: 1\n",
      "0.0581*elizabeth  0.0291*breath  0.0218*kid  0.017*take  0.017*part  0.017*move  0.0145*call  0.0145*justin  0.0121*huge  0.0121*nurs  0.0121*agenc  0.0121*week  0.0121*adopt  0.0121*kind  0.0097*last  0.0097*help  0.0097*sam  0.0097*keep  0.0097*saw  0.0097*long  \n",
      "\n",
      "Topic: 2\n",
      "0.0335*know  0.0287*like  0.0192*get  0.0192*year  0.0192*think  0.018*cancer  0.018*deni  0.0168*one  0.0144*life  0.0132*two  0.0132*anoth  0.0132*back  0.012*four  0.012*feel  0.012*lot  0.012*lar  0.012*scene  0.012*thing  0.0108*could  0.0108*diagnos  \n",
      "\n",
      "Topic: 3\n",
      "0.0519*lindsey  0.039*realli  0.0315*see  0.0278*would  0.026*like  0.0167*talk  0.0167*roy  0.0149*come  0.0149*peopl  0.0149*love  0.0149*mirror  0.0149*give  0.013*chang  0.013*someth  0.013*time  0.013*want  0.013*make  0.013*heart  0.013*gone  0.0111*notic  "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from lda import guidedlda as guidedlda\n",
    "import numpy as np\n",
    "model = guidedlda.GuidedLDA(n_topics=4,n_iter=1000,random_state=2022,refresh=10,alpha=0.01,eta=0.01)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(text2['processed'])\n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "word2id = dict((v,idx) for idx,v in enumerate(vocab))\n",
    "seed_topics = {}\n",
    "for t_id, st in enumerate(seed_words):\n",
    "    for word in st:\n",
    "        try:\n",
    "            seed_topics[word2id[word]] = t_id\n",
    "        except:\n",
    "            print(word,\" skipped\")\n",
    "\n",
    "model.fit(X.toarray(),seed_topics=seed_topics,seed_confidence=0.7) #set seed confidence to 0.7\n",
    "topic_word = model.topic_word_\n",
    "n_top_words = 20\n",
    "vocab = tuple(vocab)\n",
    "\n",
    "for i, topic_dist in enumerate(topic_word): #Print out results\n",
    "    print('\\n')\n",
    "    print('Topic:',i)\n",
    "    words_probability = np.array(-topic_dist)\n",
    "    for index in range(n_top_words):\n",
    "        print(round(abs(np.sort(words_probability))[:(n_top_words)][index],4),'*',\n",
    "              np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1][index],sep='',end='  ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lda.datasets as gldad\n",
    "# Y = gldad.load_reuters()\n",
    "# vocab_y = gldad.load_reuters_vocab()\n",
    "\n",
    "# word2id_y = dict((z, idy) for idy, z in enumerate(vocab_y))\n",
    "# print(Y[:10])\n",
    "\n",
    "# Y = guidedlda.datasets.load_data(guidedlda.datasets.NYT)\n",
    "# vocab_y = guidedlda.datasets.load_vocab(guidedlda.datasets.NYT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(vocab_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t_id, st in enumerate(bigramseed):\n",
    "#     print(t_id,st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t_id, st in enumerate(bigramseed):\n",
    "#     for word in st:\n",
    "#         try:\n",
    "#             seed_topics[word2id[word]] = t_id\n",
    "#             print(seed_topics)\n",
    "#         except:\n",
    "#             print(word, \"skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, v in enumerate(vocab):\n",
    "#     print(\"index is %d and value is %s\" % (idx, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (list(enumerate(bigramseed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proportion of Each Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_number = []\n",
    "number = []\n",
    "topic_probability = []\n",
    "for i in range(len(doc_topic)):\n",
    "    topic_number.append(doc_topic[i].argmax())\n",
    "    topic_probability.append(doc_topic[i][doc_topic[i].argmax()])\n",
    "    number.append('1')\n",
    "data = pd.DataFrame(data=[i for i in topic_number],columns=['topic_number'])\n",
    "data['number'] = [i for i in number]\n",
    "# number_of_tweets = pd.DataFrame(data.groupby('topic_number')['number'].count())\n",
    "# number_of_tweets['proportion'] = [str(round(i/len(text)*100,2))+'%' for i in number_of_tweets['number']]\n",
    "# number_of_tweets['Topic'] = ['Manufacturing process','Seafood','Meat product','Sustainability',\n",
    "#                                  'Alternative protein','Animal welfare','Health and nutrition','Industry and market',\n",
    "#                                  'Fundraising','Event promotion and media release','Hiring information',\n",
    "#                                  'Regulation','Unseeded topic1','Unseeded topic2']\n",
    "# number_of_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company-Topic Heatmap\n",
    "Based on proportion of each topic for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic = model.transform(X)\n",
    "topic_number1 = []\n",
    "\n",
    "\n",
    "for i in range(len(doc_topic)):\n",
    "    topic_number1.append(doc_topic[i].argmax())\n",
    "text2['topic number'] = [i for i in topic_number1]\n",
    "# topic_author = text2.groupby(['topic number','Company'])['tweets'].count()\n",
    "# topic_author_3d = topic_author.unstack()\n",
    "# topic_author_3d = topic_author_3d[['Memphis Meats','biftek.co 🔬👩‍🔬🐄🥗','Aleph Farms','SuperMeat',\n",
    "#                                   'Finless Foods','shiokmeats','BlueNalu','New Age Meats','CUBIQ FOODS',\n",
    "#                                   'Mosa Meat','Wildtype','Meatable','Future Fields','Vow',\n",
    "#                                   'FutureMeat','Balletic Foods','LabFarmFoods','Avant Meats','Mission Barns']]\n",
    "# topic = ['Manufacturing process and supplies','Seafood product','Meat product','Sustainability',\n",
    "#         'Animal welfare','Alternative protein','Health and nutrition','Regulation','Industry and market','Fundraising',\n",
    "#         'Hiring Information','Event promotion and media release','Unseeded topic 1','Unseeded topic 2']\n",
    "\n",
    "# company = ['UPSIDE Foods','Biftek.co','Aleph Farms','SuperMeat','Fineless Foods','Shiok Meats','BlueNalu',\n",
    "#           'New Age Meats','Cubiq Foods','Mosa Meat','Wild Type','Meatable','Future Fields','Vow','Future Meat',\n",
    "#            'Balletic Foods','Lab Farm Foods','Avant Meats','Mission Barns']\n",
    "# topic_author_3d = topic_author_3d.fillna(0)#replace NaN by 0\n",
    "# topic_author_3d = topic_author_3d.reindex([0,1,2,3,5,4,6,11,7,8,10,9,12,13])# reindex\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(11,8))\n",
    "# plt.imshow(topic_author_3d.div(topic_author_3d.sum(axis=0),axis=1),cmap=\"Blues\")\n",
    "# plt.colorbar().ax.set_ylabel('Proportion of each topic for each company')\n",
    "# plt.xticks(range(len(company)), company,rotation=90)\n",
    "# plt.yticks(range(len(topic)), topic)\n",
    "# plt.xlabel('Company')\n",
    "# plt.ylabel('Topic')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_number1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>transcripts</th>\n",
       "      <th>date</th>\n",
       "      <th>transcript_name</th>\n",
       "      <th>processed</th>\n",
       "      <th>topic number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Scene 4\\n\\nLars: [00:15:35] 35. [00:15:30]\\n\\n...</td>\n",
       "      <td>1/5/21 15:59</td>\n",
       "      <td>transcript 1</td>\n",
       "      <td>scene lar lar know bag everyth yeah yeah one t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>scene_2.wav\\nElizabeth: [00:00:01] This is my ...</td>\n",
       "      <td>12/30/20 23:14</td>\n",
       "      <td>transcript 2</td>\n",
       "      <td>scene wav elizabeth case run realli fast away ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>scene_3.wav\\nLindsey: [00:00:03] Before I was ...</td>\n",
       "      <td>12/23/20 19:00</td>\n",
       "      <td>transcript 3</td>\n",
       "      <td>scene wav lindsey diagnos still colleg found t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Scene 4\\n\\nLars: [00:15:35] 35. [00:15:30]\\n\\n...</td>\n",
       "      <td>12/16/20 21:26</td>\n",
       "      <td>transcript 4</td>\n",
       "      <td>scene lar lar know bag everyth yeah yeah one t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Scene 5\\n\\nElizabeth: [00:21:32] So [00:21:30]...</td>\n",
       "      <td>12/15/20 20:16</td>\n",
       "      <td>transcript 5</td>\n",
       "      <td>scene elizabeth saw hematologist oncologist fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Scene 6\\n\\nMaynard: [00:26:28] I noticed water...</td>\n",
       "      <td>12/10/20 0:24</td>\n",
       "      <td>transcript 6</td>\n",
       "      <td>scene maynard notic water reflect light onto s...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Scene 7\\n\\nLars: [00:28:45] Hey, [00:28:30] gu...</td>\n",
       "      <td>12/8/20 0:13</td>\n",
       "      <td>transcript 7</td>\n",
       "      <td>scene lar hey guy good job welcom camp right r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Scene 8\\n\\nLindsey: [00:31:10] I [00:31:00] ju...</td>\n",
       "      <td>12/5/20 14:13</td>\n",
       "      <td>transcript 8</td>\n",
       "      <td>scene lindsey see make feel big yet small roy ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Scene 9\\n\\nLindsey: [00:32:51] Probably. Just ...</td>\n",
       "      <td>12/3/20 23:32</td>\n",
       "      <td>transcript 9</td>\n",
       "      <td>scene lindsey probabl tri build fire get done ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Scene 10\\n\\nLindsey: [00:36:15] Oh, yeah.\\n\\nL...</td>\n",
       "      <td>11/26/20 22:05</td>\n",
       "      <td>transcript 10</td>\n",
       "      <td>scene lindsey yeah lindsey went trip septemb s...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.0</td>\n",
       "      <td>Scene 11\\n\\nLars: [00:41:00] You [00:41:00] gu...</td>\n",
       "      <td>11/24/20 20:57</td>\n",
       "      <td>transcript 11</td>\n",
       "      <td>scene lar guy turn well oil machin move river ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.0</td>\n",
       "      <td>Scene 12\\n\\nRyan: [00:44:04] feet [00:44:00] d...</td>\n",
       "      <td>11/18/20 22:50</td>\n",
       "      <td>transcript 12</td>\n",
       "      <td>scene ryan feet get cold lindsey feet got hot ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Scene 13\\n\\nElizabeth: [00:44:53] We are kind ...</td>\n",
       "      <td>11/9/20 18:47</td>\n",
       "      <td>transcript 13</td>\n",
       "      <td>scene elizabeth kind settl fact limit option s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.0</td>\n",
       "      <td>Scene 14\\n\\nLars: [00:47:43] You [00:47:30] wa...</td>\n",
       "      <td>10/30/20 20:16</td>\n",
       "      <td>transcript 14</td>\n",
       "      <td>scene lar want park boat boat littl muddi lind...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                        transcripts  \\\n",
       "0          0.0  Scene 4\\n\\nLars: [00:15:35] 35. [00:15:30]\\n\\n...   \n",
       "1          1.0  scene_2.wav\\nElizabeth: [00:00:01] This is my ...   \n",
       "2          2.0  scene_3.wav\\nLindsey: [00:00:03] Before I was ...   \n",
       "3          4.0  Scene 4\\n\\nLars: [00:15:35] 35. [00:15:30]\\n\\n...   \n",
       "4          5.0  Scene 5\\n\\nElizabeth: [00:21:32] So [00:21:30]...   \n",
       "5          6.0  Scene 6\\n\\nMaynard: [00:26:28] I noticed water...   \n",
       "6          8.0  Scene 7\\n\\nLars: [00:28:45] Hey, [00:28:30] gu...   \n",
       "7          9.0  Scene 8\\n\\nLindsey: [00:31:10] I [00:31:00] ju...   \n",
       "8         10.0  Scene 9\\n\\nLindsey: [00:32:51] Probably. Just ...   \n",
       "9         11.0  Scene 10\\n\\nLindsey: [00:36:15] Oh, yeah.\\n\\nL...   \n",
       "10        12.0  Scene 11\\n\\nLars: [00:41:00] You [00:41:00] gu...   \n",
       "11        14.0  Scene 12\\n\\nRyan: [00:44:04] feet [00:44:00] d...   \n",
       "12        15.0  Scene 13\\n\\nElizabeth: [00:44:53] We are kind ...   \n",
       "13        16.0  Scene 14\\n\\nLars: [00:47:43] You [00:47:30] wa...   \n",
       "\n",
       "              date transcript_name  \\\n",
       "0     1/5/21 15:59    transcript 1   \n",
       "1   12/30/20 23:14    transcript 2   \n",
       "2   12/23/20 19:00    transcript 3   \n",
       "3   12/16/20 21:26    transcript 4   \n",
       "4   12/15/20 20:16    transcript 5   \n",
       "5    12/10/20 0:24    transcript 6   \n",
       "6     12/8/20 0:13    transcript 7   \n",
       "7    12/5/20 14:13    transcript 8   \n",
       "8    12/3/20 23:32    transcript 9   \n",
       "9   11/26/20 22:05   transcript 10   \n",
       "10  11/24/20 20:57   transcript 11   \n",
       "11  11/18/20 22:50   transcript 12   \n",
       "12   11/9/20 18:47   transcript 13   \n",
       "13  10/30/20 20:16   transcript 14   \n",
       "\n",
       "                                            processed  topic number  \n",
       "0   scene lar lar know bag everyth yeah yeah one t...             2  \n",
       "1   scene wav elizabeth case run realli fast away ...             1  \n",
       "2   scene wav lindsey diagnos still colleg found t...             1  \n",
       "3   scene lar lar know bag everyth yeah yeah one t...             2  \n",
       "4   scene elizabeth saw hematologist oncologist fi...             0  \n",
       "5   scene maynard notic water reflect light onto s...             3  \n",
       "6   scene lar hey guy good job welcom camp right r...             0  \n",
       "7   scene lindsey see make feel big yet small roy ...             3  \n",
       "8   scene lindsey probabl tri build fire get done ...             3  \n",
       "9   scene lindsey yeah lindsey went trip septemb s...             3  \n",
       "10  scene lar guy turn well oil machin move river ...             0  \n",
       "11  scene ryan feet get cold lindsey feet got hot ...             3  \n",
       "12  scene elizabeth kind settl fact limit option s...             1  \n",
       "13  scene lar want park boat boat littl muddi lind...             0  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
